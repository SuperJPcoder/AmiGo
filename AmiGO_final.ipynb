{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UXz3FYeNA5Cv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import copy\n",
        "from collections import deque, defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PhqhRWzUAFON"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class GoGameAlphaZero:\n",
        "    def __init__(self, board_size=5):\n",
        "        self.board_size = board_size\n",
        "        self.action_size = board_size * board_size\n",
        "        self.row_count = board_size\n",
        "        self.column_count = board_size\n",
        "        self.history = []\n",
        "\n",
        "    def get_initial_state(self):\n",
        "        return np.zeros((self.board_size, self.board_size), dtype=np.int8)\n",
        "\n",
        "    def get_next_state(self, state, action, player, record_history=True):\n",
        "        row, col = divmod(action, self.board_size)\n",
        "        new_state = np.copy(state)\n",
        "        if new_state[row, col] != 0:\n",
        "            return new_state\n",
        "        new_state[row, col] = player\n",
        "        opponent = -player\n",
        "\n",
        "        for nr, nc in self.get_neighbors(row, col):\n",
        "            if new_state[nr, nc] == opponent:\n",
        "                group = self.get_group(new_state, nr, nc)\n",
        "                if not self.has_liberty(new_state, group):\n",
        "                    self.remove_group(new_state, group)\n",
        "\n",
        "        group = self.get_group(new_state, row, col)\n",
        "        if not self.has_liberty(new_state, group):\n",
        "            return state\n",
        "\n",
        "        if record_history and self.history:\n",
        "            if np.array_equal(new_state, self.history[-1]):\n",
        "                return state\n",
        "\n",
        "        if record_history:\n",
        "            self.history.append(np.copy(state))\n",
        "\n",
        "        return new_state\n",
        "\n",
        "    def get_valid_moves(self, state, player):\n",
        "        valid = np.zeros(self.action_size, dtype=np.uint8)\n",
        "        for i in range(self.action_size):\n",
        "            row, col = divmod(i, self.board_size)\n",
        "            if state[row, col] != 0:\n",
        "                continue\n",
        "            sim = self.get_next_state(state, i, player, record_history=False)\n",
        "            if not np.array_equal(sim, state):\n",
        "                valid[i] = 1\n",
        "        return valid\n",
        "\n",
        "    def get_value_and_terminated(self, state, action, player):\n",
        "      flat = state[state != 0]\n",
        "      if flat.size > 1 and np.all(flat == flat[0]):\n",
        "          return (1 if flat[0] == 1 else -1), True\n",
        "\n",
        "      valid_moves = self.get_valid_moves(state, player)\n",
        "      if np.sum(valid_moves) == 0:\n",
        "          black_stones = np.sum(state == 1)\n",
        "          white_stones = np.sum(state == -1)\n",
        "\n",
        "          if black_stones > white_stones:\n",
        "              return 1, True\n",
        "          elif white_stones > black_stones:\n",
        "              return -1, True\n",
        "          else:\n",
        "              return 0, True\n",
        "\n",
        "      return 0, False\n",
        "\n",
        "\n",
        "    def get_opponent(self, player):\n",
        "        return -player\n",
        "\n",
        "    def get_opponent_value(self, value):\n",
        "        return -value\n",
        "\n",
        "    def change_perspective(self, state, player):\n",
        "        return state * player\n",
        "\n",
        "    def get_encoded_state(self, state):\n",
        "        encoded = np.stack([\n",
        "            (state == 1).astype(np.float32),\n",
        "            (state == 0).astype(np.float32),\n",
        "            (state == -1).astype(np.float32)\n",
        "        ])\n",
        "        return encoded\n",
        "\n",
        "    def get_neighbors(self, row, col):\n",
        "        directions = [(-1,0), (1,0), (0,-1), (0,1)]\n",
        "        neighbors = []\n",
        "        for dr, dc in directions:\n",
        "            nr, nc = row + dr, col + dc\n",
        "            if 0 <= nr < self.board_size and 0 <= nc < self.board_size:\n",
        "                neighbors.append((nr, nc))\n",
        "        return neighbors\n",
        "\n",
        "    def get_group(self, board, row, col):\n",
        "        visited = set()\n",
        "        stack = [(row, col)]\n",
        "        color = board[row][col]\n",
        "        group = []\n",
        "        while stack:\n",
        "            r, c = stack.pop()\n",
        "            if (r, c) not in visited and board[r, c] == color:\n",
        "                visited.add((r, c))\n",
        "                group.append((r, c))\n",
        "                for nr, nc in self.get_neighbors(r, c):\n",
        "                    if board[nr, nc] == color:\n",
        "                        stack.append((nr, nc))\n",
        "        return group\n",
        "\n",
        "    def has_liberty(self, board, group):\n",
        "        for r, c in group:\n",
        "            for nr, nc in self.get_neighbors(r, c):\n",
        "                if board[nr, nc] == 0:\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def remove_group(self, board, group):\n",
        "        for r, c in group:\n",
        "            board[r, c] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9294pxN4BbW7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, game, num_resBlocks=5, num_hidden=128):\n",
        "        super().__init__()\n",
        "        self.board_height = game.row_count\n",
        "        self.board_width = game.column_count\n",
        "        self.action_size = game.action_size\n",
        "\n",
        "        self.startBlock = nn.Sequential(\n",
        "            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_hidden),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.backBone = nn.ModuleList(\n",
        "            [ResBlock(num_hidden) for _ in range(num_resBlocks)]\n",
        "        )\n",
        "\n",
        "        self.policyHead = nn.Sequential(\n",
        "            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * self.board_height * self.board_width, self.action_size)\n",
        "        )\n",
        "\n",
        "        self.valueHead = nn.Sequential(\n",
        "            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3 * self.board_height * self.board_width, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.startBlock(x)\n",
        "        for block in self.backBone:\n",
        "            x = block(x)\n",
        "        policy = self.policyHead(x)\n",
        "        value = self.valueHead(x)\n",
        "        return policy, value\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, num_hidden):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
        "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += identity\n",
        "        out = F.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "id": "GOAj_PYgB--T",
        "outputId": "0432c53c-b3e7-40c5-add8-0607b3722a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0]\n",
            " [ 0  1  1  0  0]\n",
            " [ 0  0 -1  0  0]\n",
            " [ 0  0  0  0  0]\n",
            " [ 0  0  0  0  0]]\n",
            "[[[0. 0. 0. 0. 0.]\n",
            "  [0. 1. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 1. 1. 1. 1.]\n",
            "  [1. 0. 0. 1. 1.]\n",
            "  [1. 1. 0. 1. 1.]\n",
            "  [1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]]\n",
            "0.4322153925895691 [0.03296572 0.03657424 0.03395321 0.06085989 0.04435472 0.07760715\n",
            " 0.05033949 0.01246351 0.04032004 0.03280267 0.05087126 0.03375656\n",
            " 0.02086587 0.01915121 0.04730298 0.02592663 0.02049106 0.02626669\n",
            " 0.03416865 0.03969342 0.04378238 0.04130181 0.01873302 0.03566273\n",
            " 0.11978514]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "game = GoGameAlphaZero(board_size=5)\n",
        "\n",
        "state = game.get_initial_state()\n",
        "state = game.get_next_state(state, 6, 1)\n",
        "state = game.get_next_state(state, 12, -1)\n",
        "state = game.get_next_state(state, 7, 1)\n",
        "\n",
        "print(state)\n",
        "\n",
        "encoded_state = game.get_encoded_state(state)\n",
        "print(encoded_state)\n",
        "\n",
        "tensor_state = torch.tensor(encoded_state).unsqueeze(0)\n",
        "\n",
        "model = ResNet(game, num_resBlocks=4, num_hidden=64)\n",
        "\n",
        "policy, value = model(tensor_state)\n",
        "value = value.item()\n",
        "policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
        "\n",
        "print(value, policy)\n",
        "\n",
        "plt.bar(range(game.action_size), policy)\n",
        "plt.title(\"Policy distribution over actions\")\n",
        "plt.xlabel(\"Action (flattened board index)\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hdyq2zc4DtPt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, game, args, state, player, parent=None, action_taken=None, prior=0):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.state = state\n",
        "        self.player = player\n",
        "        self.parent = parent\n",
        "        self.action_taken = action_taken\n",
        "        self.prior = prior\n",
        "\n",
        "        self.children = []\n",
        "        self.visit_count = 0\n",
        "        self.value_sum = 0\n",
        "\n",
        "    def is_fully_expanded(self):\n",
        "        return len(self.children) > 0\n",
        "\n",
        "    def select(self):\n",
        "        best_child = None\n",
        "        best_ucb = -np.inf\n",
        "        for child in self.children:\n",
        "            ucb = self._ucb_score(child)\n",
        "            if ucb > best_ucb:\n",
        "                best_ucb = ucb\n",
        "                best_child = child\n",
        "        return best_child\n",
        "\n",
        "    def _ucb_score(self, child):\n",
        "        if child.visit_count == 0:\n",
        "            q_value = 0\n",
        "        else:\n",
        "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
        "        exploration = self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1))\n",
        "        return q_value + exploration * child.prior\n",
        "\n",
        "    def expand(self, policy):\n",
        "        valid = self.game.get_valid_moves(self.state, self.player)\n",
        "        next_player = -self.player\n",
        "        for action, prob in enumerate(policy):\n",
        "            if prob > 0 and valid[action]:\n",
        "                child_state = self.game.get_next_state(\n",
        "                    self.state.copy(), action, self.player, record_history=False\n",
        "                )\n",
        "                if not np.array_equal(child_state, self.state):\n",
        "                    child = Node(\n",
        "                        self.game,\n",
        "                        self.args,\n",
        "                        child_state,\n",
        "                        next_player,\n",
        "                        self,\n",
        "                        action,\n",
        "                        prob\n",
        "                    )\n",
        "                    self.children.append(child)\n",
        "        return self.children\n",
        "\n",
        "\n",
        "\n",
        "    def backpropagate(self, value):\n",
        "        self.value_sum += value\n",
        "        self.visit_count += 1\n",
        "        if self.parent:\n",
        "            self.parent.backpropagate(-value)\n",
        "\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, game, args, model, device):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "    @torch.no_grad()\n",
        "    def search(self, state, player=1):\n",
        "        root = Node(self.game, self.args, state, player)\n",
        "\n",
        "        for _ in range(self.args['num_searches']):\n",
        "            node = root\n",
        "            path = []\n",
        "            while node.is_fully_expanded():\n",
        "                node = node.select()\n",
        "                path.append(node)\n",
        "\n",
        "            value, is_terminal = self.game.get_value_and_terminated(\n",
        "                node.state, node.action_taken, node.player)\n",
        "\n",
        "            if not is_terminal:\n",
        "                flipped = self.game.change_perspective(node.state, node.player)\n",
        "                encoded = self.game.get_encoded_state(flipped)\n",
        "                tensor = torch.tensor(encoded).unsqueeze(0).to(self.device)\n",
        "\n",
        "                policy_logits, value_tensor = self.model(tensor)\n",
        "                probs = torch.softmax(policy_logits, dim=1).squeeze(0).cpu().numpy()\n",
        "\n",
        "                valid = self.game.get_valid_moves(flipped, node.player)\n",
        "                probs *= valid\n",
        "                if probs.sum() > 0:\n",
        "                    probs /= probs.sum()\n",
        "                else:\n",
        "                    probs = valid / valid.sum()\n",
        "\n",
        "                node.expand(probs)\n",
        "                value = value_tensor.item()\n",
        "\n",
        "            node.backpropagate(value)\n",
        "\n",
        "        visits = np.zeros(self.game.action_size)\n",
        "        for child in root.children:\n",
        "            visits[child.action_taken] = child.visit_count\n",
        "        if visits.sum() > 0:\n",
        "            return visits / visits.sum()\n",
        "        return np.ones(self.game.action_size) / self.game.action_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PBwuBDvPi-l"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import trange\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "class AlphaZero:\n",
        "    def __init__(self, model, optimizer, game, args):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.mcts = MCTS(game, args, self.model, self.device)\n",
        "        self.best_model_state = self.model.state_dict()\n",
        "        self.best_win_rate = 0\n",
        "\n",
        "    def selfPlay(self):\n",
        "        memory = []\n",
        "        player = 1\n",
        "        state = self.game.get_initial_state()\n",
        "        temperature = self.args.get('temperature', 1.0)\n",
        "\n",
        "        while True:\n",
        "            neutral_state = self.game.change_perspective(state, player)\n",
        "            action_probs = self.mcts.search(neutral_state, player)\n",
        "\n",
        "            if np.sum(action_probs) == 0 or np.any(np.isnan(action_probs)):\n",
        "                action_probs = np.ones(self.game.action_size) / self.game.action_size\n",
        "\n",
        "            if temperature != 1.0:\n",
        "                action_probs = np.power(action_probs, 1/temperature)\n",
        "                action_probs /= np.sum(action_probs)\n",
        "\n",
        "            memory.append((neutral_state, action_probs, player))\n",
        "            action = np.random.choice(self.game.action_size, p=action_probs)\n",
        "            state = self.game.get_next_state(state, action, player)\n",
        "\n",
        "            value, is_terminal = self.game.get_value_and_terminated(state, action, player)\n",
        "\n",
        "            if is_terminal:\n",
        "                returnMemory = []\n",
        "                for hist_state, hist_probs, hist_player in memory:\n",
        "                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
        "                    encoded = self.game.get_encoded_state(hist_state)\n",
        "                    encoded_tensor = torch.tensor(encoded, dtype=torch.float32).to(self.device)\n",
        "                    returnMemory.append((\n",
        "                        encoded_tensor.cpu().numpy(),\n",
        "                        hist_probs,\n",
        "                        hist_outcome\n",
        "                    ))\n",
        "                return returnMemory\n",
        "\n",
        "            player = self.game.get_opponent(player)\n",
        "\n",
        "    def train(self, memory):\n",
        "        batch_size = self.args.get('batch_size', 128)\n",
        "        np.random.shuffle(memory)\n",
        "\n",
        "        for i in range(0, len(memory), batch_size):\n",
        "            batch = memory[i:i+batch_size]\n",
        "            state_batch, policy_batch, value_batch = zip(*batch)\n",
        "\n",
        "            state_batch = torch.tensor(np.array(state_batch), dtype=torch.float32).to(self.device)\n",
        "            policy_batch = torch.tensor(np.array(policy_batch), dtype=torch.float32).to(self.device)\n",
        "            value_batch = torch.tensor(np.array(value_batch), dtype=torch.float32).view(-1,1).to(self.device)\n",
        "\n",
        "            pred_policy, pred_value = self.model(state_batch)\n",
        "\n",
        "            policy_loss = -(policy_batch * torch.log_softmax(pred_policy, dim=1)).sum(dim=1).mean()\n",
        "            value_loss = torch.mean((value_batch - pred_value)**2)\n",
        "\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    def evaluate_model(self, iterations=10):\n",
        "        wins = 0\n",
        "        for _ in range(iterations):\n",
        "            winner = self.play_game(self.model, self.best_model_state)\n",
        "            if winner == 1:\n",
        "                wins += 1\n",
        "        return wins / iterations\n",
        "\n",
        "    def play_game(self, new_model, old_model_state):\n",
        "        temp_model = ResNet(self.game,\n",
        "                            num_resBlocks=self.args['num_resBlocks'],\n",
        "                            num_hidden=self.args['num_hidden']).to(self.device)\n",
        "        temp_model.load_state_dict(old_model_state)\n",
        "        new_mcts = MCTS(self.game, self.args, new_model, self.device)\n",
        "        old_mcts = MCTS(self.game, self.args, temp_model, self.device)\n",
        "\n",
        "        state = self.game.get_initial_state()\n",
        "        player = 1\n",
        "\n",
        "        while True:\n",
        "            neutral_state = self.game.change_perspective(state, player)\n",
        "            mcts = new_mcts if player == 1 else old_mcts\n",
        "            action_probs = mcts.search(neutral_state, player)\n",
        "            action = np.argmax(action_probs)\n",
        "\n",
        "            state = self.game.get_next_state(state, action, player)\n",
        "            value, is_terminal = self.game.get_value_and_terminated(state, action, player)\n",
        "\n",
        "            if is_terminal:\n",
        "                return player if value == 1 else self.game.get_opponent(player)\n",
        "\n",
        "            player = self.game.get_opponent(player)\n",
        "\n",
        "    def learn(self):\n",
        "        for iteration in range(self.args['num_iterations']):\n",
        "            memory = []\n",
        "            self.model.eval()\n",
        "\n",
        "            for _ in trange(self.args['num_selfPlay_iterations'],\n",
        "                            desc=f\"Self-play Iteration {iteration+1}\"):\n",
        "                memory += self.selfPlay()\n",
        "\n",
        "            self.model.train()\n",
        "            for _ in trange(self.args['num_epochs'],\n",
        "                            desc=f\"Training Epochs {iteration+1}\"):\n",
        "                self.train(memory)\n",
        "\n",
        "            win_rate = self.evaluate_model(iterations=self.args.get('evaluation_games', 10))\n",
        "            print(f\"Evaluation win rate at iteration {iteration}: {win_rate:.2f}\")\n",
        "\n",
        "            if win_rate > self.best_win_rate:\n",
        "                self.best_win_rate = win_rate\n",
        "                self.best_model_state = self.model.state_dict()\n",
        "                torch.save(self.best_model_state, \"best_model.pt\")\n",
        "                print(f\"New best model saved with win rate {win_rate:.2f}\")\n",
        "\n",
        "            torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n",
        "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    game = GoGameAlphaZero()\n",
        "    model = ResNet(game, num_resBlocks=4, num_hidden=64)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    args = {\n",
        "        'C': 2,\n",
        "        'num_searches': 100,\n",
        "        'num_iterations': 50,\n",
        "        'num_selfPlay_iterations': 50,\n",
        "        'num_epochs': 8,\n",
        "        'batch_size': 128,\n",
        "        'evaluation_games': 10,\n",
        "        'temperature': 1.0,\n",
        "        'num_resBlocks': 4,\n",
        "        'num_hidden': 64\n",
        "    }\n",
        "\n",
        "    alphaZero = AlphaZero(model, optimizer, game, args)\n",
        "    alphaZero.learn()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG_8-evAeFas",
        "outputId": "f1a0e4eb-89e4-4e51-ad5b-3dc49390d1cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "5 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 1\n",
            "Enter col (1-5): 1\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "5 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a064cafbed86>:103: RuntimeWarning: invalid value encountered in divide\n",
            "  probs = valid / valid.sum()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI plays: (4, 4)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   |   |   | W |   |\n",
            "  +---+---+---+---+---+\n",
            "5 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 2\n",
            "Enter col (1-5): 3\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   |   | B |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   |   |   | W |   |\n",
            "  +---+---+---+---+---+\n",
            "5 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (3, 4)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   |   | B |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   |   | W |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   |   |   | W |   |\n",
            "  +---+---+---+---+---+\n",
            "5 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 3\n",
            "Enter col (1-5): 3\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   |   | B |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   |   |   | W |   |\n",
            "  +---+---+---+---+---+\n",
            "5 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (4, 2)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   |   | B |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W |   | W |   |\n",
            "  +---+---+---+---+---+\n",
            "5 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 4\n",
            "Enter col (1-5): 3\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   |   | B |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "5 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (2, 2)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "5 |   |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 5\n",
            "Enter col (1-5): 4\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "5 |   |   |   | B |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (5, 2)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W |   | B |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 4\n",
            "Enter col (1-5): 5\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   |   | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W |   | B |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (3, 2)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W |   | B |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 3\n",
            "Enter col (1-5): 5\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B |   |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W |   | B |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (2, 4)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B | W |   |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W |   | B |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 2\n",
            "Enter col (1-5): 5\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   |   |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W |   | B |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (1, 4)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B |   |   | W |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W |   | B |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 1\n",
            "Enter col (1-5): 2\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B | B |   | W |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "4 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W |   | B |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (4, 1)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B | B |   | W |   |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "4 | W | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W |   | B |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 1\n",
            "Enter col (1-5): 5\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B | B |   | W | B |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "4 | W | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W |   | B |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (5, 3)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B | B |   | W | B |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "4 | W | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W | W | B |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 1\n",
            "Enter col (1-5): 3\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B | B | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "4 | W | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W | W | B |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (4, 4)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B | B | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "4 | W | W | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W | W | B |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 3\n",
            "Enter col (1-5): 4\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B | B | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "3 |   | W | B | B | B |\n",
            "  +---+---+---+---+---+\n",
            "4 | W | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W | W | B |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (3, 1)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B | B | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "2 |   | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "3 | W | W | B | B | B |\n",
            "  +---+---+---+---+---+\n",
            "4 | W | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W | W | B |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 2\n",
            "Enter col (1-5): 1\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B | B | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "2 | B | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "3 | W | W | B | B | B |\n",
            "  +---+---+---+---+---+\n",
            "4 | W | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W | W | B |   |\n",
            "  +---+---+---+---+---+\n",
            "AI is thinking...\n",
            "AI plays: (1, 4)\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B | B | B | W | B |\n",
            "  +---+---+---+---+---+\n",
            "2 | B | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "3 | W | W | B | B | B |\n",
            "  +---+---+---+---+---+\n",
            "4 | W | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W | W | B |   |\n",
            "  +---+---+---+---+---+\n",
            "Enter row (1-5): 2\n",
            "Enter col (1-5): 4\n",
            "    1   2   3   4   5  \n",
            "  +---+---+---+---+---+\n",
            "1 | B | B | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "2 | B | W | B | B | B |\n",
            "  +---+---+---+---+---+\n",
            "3 | W | W | B | B | B |\n",
            "  +---+---+---+---+---+\n",
            "4 | W | W | B |   | B |\n",
            "  +---+---+---+---+---+\n",
            "5 |   | W | W | B |   |\n",
            "  +---+---+---+---+---+\n",
            "Black wins!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "game = GoGameAlphaZero()\n",
        "player = 1\n",
        "\n",
        "def print_board(state):\n",
        "    print(\"   \", end='')\n",
        "    for col in range(1, game.column_count + 1):\n",
        "        print(f\" {col}  \", end='')\n",
        "    print(\"\\n  +\" + \"---+\" * game.column_count)\n",
        "    for i, row in enumerate(state):\n",
        "        print(f\"{i+1} |\", end='')\n",
        "        for cell in row:\n",
        "            if cell == 1:\n",
        "                print(\" B |\", end='')\n",
        "            elif cell == -1:\n",
        "                print(\" W |\", end='')\n",
        "            else:\n",
        "                print(\"   |\", end='')\n",
        "        print(\"\\n  +\" + \"---+\" * game.column_count)\n",
        "\n",
        "args = {'C': 2, 'num_searches': 1000}\n",
        "model = ResNet(game, num_resBlocks=4, num_hidden=64)\n",
        "model.load_state_dict(torch.load(\"model_19.pt\", map_location=torch.device(\"cpu\")))\n",
        "model.eval()\n",
        "mcts = MCTS(game, args, model, device=torch.device(\"cpu\"))\n",
        "\n",
        "state = game.get_initial_state()\n",
        "\n",
        "while True:\n",
        "    print_board(state)\n",
        "\n",
        "    valid_moves = game.get_valid_moves(state, player)\n",
        "    valid_idxs = [i for i, v in enumerate(valid_moves) if v]\n",
        "\n",
        "    if player == 1:\n",
        "        if not valid_idxs:\n",
        "            value, _ = game.get_value_and_terminated(state, None, player)\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            r = int(input(\"Enter row (1-5): \")) - 1\n",
        "            c = int(input(\"Enter col (1-5): \")) - 1\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Use numbers 15.\")\n",
        "            continue\n",
        "\n",
        "        if not (0 <= r < game.row_count and 0 <= c < game.column_count):\n",
        "            print(\"Out of bounds. Try again.\")\n",
        "            continue\n",
        "\n",
        "        action = r * game.column_count + c\n",
        "        if action not in valid_idxs:\n",
        "            print(\"Illegal move. Try again.\")\n",
        "            continue\n",
        "\n",
        "        new_state = game.get_next_state(state, action, player)\n",
        "        if np.array_equal(new_state, state):\n",
        "            print(\"Invalid move (Ko or suicide). Try again.\")\n",
        "            continue\n",
        "\n",
        "        state = new_state\n",
        "        player = game.get_opponent(player)\n",
        "\n",
        "    else:\n",
        "        if not valid_moves.any():\n",
        "            value, _ = game.get_value_and_terminated(state, None, player)\n",
        "            break\n",
        "\n",
        "        print(\"AI is thinking...\")\n",
        "        probs = mcts.search(state, player)\n",
        "        valid = game.get_valid_moves(state, player)\n",
        "        probs *= valid\n",
        "        if probs.sum() == 0:\n",
        "            probs = valid / valid.sum()\n",
        "        else:\n",
        "            probs /= probs.sum()\n",
        "\n",
        "        action = int(np.argmax(probs))\n",
        "        if not valid[action]:\n",
        "            valid_probs = probs * valid\n",
        "            if valid_probs.sum() > 0:\n",
        "                action = int(np.argmax(valid_probs))\n",
        "            else:\n",
        "                action = np.random.choice(np.where(valid)[0])\n",
        "\n",
        "        r, c = divmod(action, game.column_count)\n",
        "        print(f\"AI plays: ({r+1}, {c+1})\")\n",
        "\n",
        "        state = game.get_next_state(state, action, player)\n",
        "        player = game.get_opponent(player)\n",
        "\n",
        "    value, is_term = game.get_value_and_terminated(state, action, player)\n",
        "    if is_term:\n",
        "        break\n",
        "\n",
        "print_board(state)\n",
        "if value == 1:\n",
        "    print(\"Black wins!\")\n",
        "elif value == -1:\n",
        "    print(\"White wins!\")\n",
        "else:\n",
        "    print(\"Draw!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOQwO2eOfvv6ucBewwaGjL1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}